{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('/data2', 'EgoExo4D')\n",
    "features_dir = os.path.join(data_dir, 'features', 'omnivore_video')\n",
    "file_id = '1656ad38-2a4d-4561-a077-a646e24812a4_aria01_rgb.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = torch.load(os.path.join(features_dir, file_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VRS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ego_exo_root = os.path.join('/data2', 'EgoExo4D') # Replace with your cli's download directory for Ego-Exo4D\n",
    "take_name = 'cmu_bike01_5'\n",
    "\n",
    "ego_exo_project_path = os.path.join(ego_exo_root, 'takes', take_name)\n",
    "print(f'EgoExo Sequence: {ego_exo_project_path}')\n",
    "\n",
    "if not os.path.exists(ego_exo_project_path):\n",
    "    print(\"Please do update your path to a valid EgoExo sequence folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectaria_tools.core import data_provider\n",
    "\n",
    "vrs_file_path = os.path.join(ego_exo_project_path, 'aria01_noimagestreams.vrs')\n",
    "print(vrs_file_path)\n",
    "assert os.path.exists(vrs_file_path), \"We are not finding the required vrs file\"\n",
    "\n",
    "vrs_data_provider = data_provider.create_vrs_data_provider(vrs_file_path)\n",
    "if not vrs_data_provider:\n",
    "    print(\"Couldn't create data vrs_data_provider from vrs file\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectaria_tools.core.stream_id import StreamId\n",
    "from projectaria_tools.core.sensor_data import TimeDomain, TimeQueryOptions\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "###\n",
    "# We are demonstrating here how to retrieve the time stamp of a given stream\n",
    "# - and how to retrieve 10 frames along this time span\n",
    "###\n",
    "\n",
    "# rgb_stream_id = StreamId(\"214-1\")\n",
    "slam_left_stream_id = StreamId(\"1201-1\")\n",
    "slam_right_stream_id = StreamId(\"1201-2\")\n",
    "# rgb_stream_label = vrs_data_provider.get_label_from_stream_id(rgb_stream_id)\n",
    "slam_left_stream_label = vrs_data_provider.get_label_from_stream_id(slam_left_stream_id)\n",
    "slam_right_stream_label = vrs_data_provider.get_label_from_stream_id(slam_right_stream_id)\n",
    "\n",
    "# Init rerun api\n",
    "# rr.init(\"Aria Data Provider - Retrieve Image Stream data\")\n",
    "# rec = rr.memory_recording()\n",
    "\n",
    "# Configure option for data retrieval\n",
    "time_domain = TimeDomain.DEVICE_TIME  # query data based on host time\n",
    "option = TimeQueryOptions.CLOSEST # get data whose time [in TimeDomain] is CLOSEST to query time\n",
    "# vrs_data_provider.get_imu_data_by_time_ns()\n",
    "# Retrieve Start and End time for the given Sensor Stream Id\n",
    "start_time = vrs_data_provider.get_first_time_ns(slam_left_stream_id, time_domain)\n",
    "end_time = vrs_data_provider.get_last_time_ns(slam_left_stream_id, time_domain)\n",
    "\n",
    "# FYI, you can retrieve the Image configuration using the following\n",
    "image_config = vrs_data_provider.get_image_configuration(slam_left_stream_id)\n",
    "width = image_config.image_width\n",
    "height = image_config.image_height\n",
    "print(f\"StreamId {slam_left_stream_id}, StreamLabel {slam_left_stream_label}, ImageSize: {width, height}\")\n",
    "\n",
    "sample_count = 10\n",
    "sample_timestamps = np.linspace(start_time, end_time, sample_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_id = vrs_data_provider.get_stream_id_from_label(\"imu-left\")\n",
    "\n",
    "accl = []\n",
    "gyro = []\n",
    "ts_ns = []\n",
    "\n",
    "for index in range(0, int(vrs_data_provider.get_num_data(stream_id) / 10)):\n",
    "\n",
    "    imu_data = vrs_data_provider.get_imu_data_by_index(stream_id, index)\n",
    "    timestamp = imu_data.capture_timestamp_ns\n",
    "    ts_ns.append(timestamp)\n",
    "    accl.append(imu_data.accel_msec2),\n",
    "    gyro.append(imu_data.gyro_radsec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(accl), len(gyro), len(ts_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vrs_data_provider.get_num_data(stream_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = vrs_data_provider.get_first_time_ns(stream_id, time_domain)\n",
    "end_time = vrs_data_provider.get_last_time_ns(stream_id, time_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(start_time / 1e9, end_time / 1e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takes metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Load the json file\n",
    "# takes = pd.read_json(os.path.join(ego_exo_root, 'takes.json'))\n",
    "ego_exo_root = os.path.join('/data2', 'EgoExo4D') # Replace with your cli's download directory for Ego-Exo4D\n",
    "data_dir = os.path.join('/data2', 'EgoExo4D')\n",
    "takes = json.load(open(os.path.join(ego_exo_root, 'takes.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "takes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectaria_tools.core.stream_id import StreamId\n",
    "from projectaria_tools.core.sensor_data import TimeDomain, TimeQueryOptions\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_take_vrs_file(take_root_dir: os.PathLike):\n",
    "    '''\n",
    "    Get both IMU streams from the VRS file\n",
    "    '''\n",
    "    from projectaria_tools.core import data_provider\n",
    "\n",
    "    # Get the VRS file\n",
    "    vrs_file_path = os.path.join(take_root_dir, 'aria01_noimagestreams.vrs')\n",
    "    assert os.path.exists(vrs_file_path), \"We are not finding the required vrs file\"\n",
    "\n",
    "    # Create the VRS data provider\n",
    "    vrs_data_provider = data_provider.create_vrs_data_provider(vrs_file_path)\n",
    "    if not vrs_data_provider:\n",
    "        # print(\"Couldn't create data vrs_data_provider from vrs file\")\n",
    "        exit(1)\n",
    "    \n",
    "    return vrs_data_provider\n",
    "\n",
    "def get_imu_data(vrs_data_provider, stream_labels: list[str]):\n",
    "    '''\n",
    "    Get both IMU streams from the VRS file.\n",
    "\n",
    "    Args:\n",
    "    - vrs_data_provider: the VRS data provider\n",
    "    - stream_labels: the labels of the streams to retrieve. ['imu-left', 'imu-right']\n",
    "\n",
    "    '''\n",
    "    stream_id = vrs_data_provider.get_stream_id_from_label(stream_labels[0])\n",
    "    assert stream_id, f\"Couldn't find stream id for {stream_labels[0]}\"\n",
    "\n",
    "    '''\n",
    "    For each stream, we will get the IMU data for a total of 7 columns:\n",
    "    - timestamps (in ns)\n",
    "    - accelerometer data (in m/s^2) (x, y, z)\n",
    "    - gyroscope data (in rad/sec) (x, y, z)\n",
    "    '''\n",
    "    left = np.zeros((vrs_data_provider.get_num_data(stream_id), 7))\n",
    "    right = np.zeros((vrs_data_provider.get_num_data(stream_id), 7))\n",
    "\n",
    "    for idx, stream_label in enumerate(stream_labels):\n",
    "        stream_id = vrs_data_provider.get_stream_id_from_label(stream_label)\n",
    "\n",
    "        for index in range(int(vrs_data_provider.get_num_data(stream_id))):\n",
    "            imu_data = vrs_data_provider.get_imu_data_by_index(stream_id, index)\n",
    "            timestamp = imu_data.capture_timestamp_ns\n",
    "            try:\n",
    "                if stream_label.endswith('left'):\n",
    "                    left[index, 0] = timestamp\n",
    "                    left[index, 1:4] = imu_data.accel_msec2\n",
    "                    left[index, 4:] = imu_data.gyro_radsec\n",
    "                else:\n",
    "                    right[index, 0] = timestamp\n",
    "                    right[index, 1:4] = imu_data.accel_msec2\n",
    "                    right[index, 4:] = imu_data.gyro_radsec\n",
    "            except:\n",
    "                \"skipping\"\n",
    "\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "missing_files = []\n",
    "imu_path = os.path.join(data_dir, 'features', 'imu_aria01')\n",
    "print(\"start\")\n",
    "for idx, take in enumerate(tqdm(takes, total=len(takes))):\n",
    "    take_vrs_path = os.path.join(data_dir ,take['root_dir'])\n",
    "    try:\n",
    "        data_provider = get_take_vrs_file(take_vrs_path)\n",
    "        # left, right = get_imu_data(data_provider,['imu-left', 'imu-right'])\n",
    "        _, right = get_imu_data(data_provider,['imu-right'])\n",
    "        take_name = take['take_name']\n",
    "        path_take = os.path.join(imu_path, f\"{take_name}\")\n",
    "        if not os.path.exists(path_take):\n",
    "            os.makedirs(path_take)\n",
    "        # np.save(os.path.join(path_take, 'left.npy'), left)\n",
    "        np.save(os.path.join(path_take, 'right.npy'), right)\n",
    "\n",
    "    except:\n",
    "        missing_files.append(take_vrs_path)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left.shape, right.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova_left, prova_right = left[0,0] / 1e9, right[0,0] / 1e9\n",
    "prova_left, prova_right = prova_left.round(4), prova_right.round(4)\n",
    "prova_left, prova_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = right.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(right[0,-1] - right[0,0]) / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Missing takes: ', len(missing_files))\n",
    "missing_files_path = os.path.join('../data', 'EgoExo4D', 'missing_files.npy')\n",
    "os.makedirs(os.path.dirname(missing_files_path), exist_ok=True)\n",
    "np.save(missing_files_path, missing_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pretraining metadata with omnivore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Load the json file\n",
    "# takes = pd.read_json(os.path.join(ego_exo_root, 'takes.json'))\n",
    "ego_exo_root = os.path.join('/data2', 'EgoExo4D') # Replace with your cli's download directory for Ego-Exo4D\n",
    "data_dir = os.path.join('/data2', 'EgoExo4D')\n",
    "takes = json.load(open(os.path.join(ego_exo_root, 'takes.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectaria_tools.core import data_provider\n",
    "from projectaria_tools.core.sensor_data import TimeDomain, TimeQueryOptions\n",
    "from projectaria_tools.core.stream_id import StreamId\n",
    "\n",
    "take_root_dir = os.path.join(data_dir, takes[0]['root_dir'])\n",
    "# Get the VRS file\n",
    "vrs_file_path = os.path.join(take_root_dir, 'aria01_noimagestreams.vrs')\n",
    "assert os.path.exists(vrs_file_path), \"We are not finding the required vrs file\"\n",
    "\n",
    "# Create the VRS data provider\n",
    "vrs_data_provider = data_provider.create_vrs_data_provider(vrs_file_path)\n",
    "stream_id = vrs_data_provider.get_stream_id_from_label(\"imu-left\")\n",
    "query_timestamp = takes[0]['task_start_sec'] * 1e9\n",
    "sensor_data = vrs_data_provider.get_imu_data_by_time_ns(stream_id, query_timestamp, TimeDomain.DEVICE_TIME, TimeQueryOptions.AFTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = []\n",
    "for data in vrs_data_provider.deliver_queued_sensor_data():\n",
    "    ts.append(data.get_time_ns(TimeDomain.DEVICE_TIME) / 1e9)\n",
    "max(ts), min(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "takes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10498 - 7170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      3\u001b[0m annotations_pretrain \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m features_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "annotations_pretrain = []\n",
    "\n",
    "features_path = os.path.join(data_dir, 'features')\n",
    "print(\"start\")\n",
    "for idx, take in enumerate(tqdm(takes, total=len(takes))):\n",
    "    take_imu_path = os.path.join(imu_path,'imu_aria01', take['take_name'])\n",
    "    start_sec = take['task_start_sec']\n",
    "    end_sec = take['task_end_sec']\n",
    "    take_duration = take['duration_sec']\n",
    "\n",
    "    omnivore_file = torch.load(os.path.join(features_path, 'omnivore_video', f\"{take['name']}_aria01_rgb.pt\"))\n",
    "    num_frames = omnivore_file.shape[0]\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "207 * 16 / 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('/data2', 'EgoExo4D', 'features', 'imu_aria01', takes[0]['take_name'])\n",
    "data = np.load(os.path.join(data_dir, 'right.npy')).T\n",
    "data_rounded = deepcopy(data)\n",
    "data_rounded[0, :] = np.round(data[0, :] / 1e9, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][-1], data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rounded[0, -1] - data_rounded[0, 0], data_rounded[0, -1], data_rounded[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "takes[0]['task_end_sec'], takes[0]['task_start_sec'], takes[0]['duration_sec']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torchaudio\n",
    "import librosa\n",
    "import torchaudio.transforms as T\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('/data2', 'EgoExo4D', 'features', 'imu_aria01', 'cmu_bike01_5')\n",
    "data = np.load(os.path.join(data_dir, 'right.npy')).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.round(np.diff(data[0, :]) / 1e9, 3)\n",
    "max(diff), min(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rounded = data\n",
    "data_rounded[0, :] = np.round(data[0, :] / 1e9, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor = torch.tensor(data_rounded[1:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(diff)\n",
    "plt.title('Linear Plot of diff')\n",
    "plt.xlabel('time (ms)')\n",
    "plt.ylabel('delta (in ms)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate * seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds = 2\n",
    "sample_rate = 1e3\n",
    "start = 500\n",
    "windowed_data = data_tensor[:, start:int(start + seconds * sample_rate)]\n",
    "windowed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_data.max(), windowed_data.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tensor(tensor):\n",
    "    tensor = torch.from_numpy(tensor)\n",
    "    min_value = torch.min(tensor)\n",
    "    max_value = torch.max(tensor)\n",
    "    normalized_tensor = (tensor - min_value) / (max_value - min_value)\n",
    "    return normalized_tensor\n",
    "\n",
    "def plot_spectrogram(specgram, title=None, ylabel=\"freq_bin\", ax=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, 1)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.imshow(specgram, origin=\"lower\", aspect=\"auto\", interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECGRAM_PARAMS = {\n",
    "    'window_size': 2,\n",
    "    'n_fft': 128,\n",
    "    'hop_length': 4,\n",
    "    'sampling_rate': 1e3,\n",
    "    'downsampling_rate': 500,\n",
    "    'transforms': None,\n",
    "    'resizes': (64, 192), # patch_size=16 -> (4, 12) = 48 | patch_size=8 -> (8, 24) = 192\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova_2s = torchaudio.functional.resample(windowed_data, 1e3, 500)\n",
    "# prova_2s = accl_x_interp_torch\n",
    "# prova_2s = normalize_tensor(prova_2s.numpy())\n",
    "# \n",
    "\n",
    "n_ffts = [128, 256]\n",
    "hop_length = [2, 4, 8, 16]\n",
    "amplitude_to_db = T.AmplitudeToDB(stype=\"power\", top_db=90)\n",
    "specs = []\n",
    "for i, n_fft in enumerate(n_ffts):\n",
    "    spectrogram = T.Spectrogram(\n",
    "        n_fft=n_fft,\n",
    "        hop_length=4,\n",
    "        center=True,\n",
    "        pad_mode=\"reflect\",\n",
    "        power=2.0,\n",
    "        normalized=True,\n",
    "        window_fn=torch.signal.windows.nuttall\n",
    "    )\n",
    "    spectrogram.double()\n",
    "\n",
    "    # 1. spettrogramma\n",
    "    # 2. da amplitude a dB\n",
    "    # 3. normalizzare [0,1]\n",
    "    prova = spectrogram(prova_2s)\n",
    "    # prova = librosa.power_to_db(prova)\n",
    "    prova = amplitude_to_db(prova)\n",
    "    # prova = normalize_tensor(prova.numpy())\n",
    "    specs.append(prova)\n",
    "    \n",
    "for i in range(len(specs)):\n",
    "    print(specs[i].shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(specs), figsize=(20,4))\n",
    "for i, (spec, n_fft) in enumerate(zip(specs, n_ffts)):\n",
    "    plot_spectrogram(spec[0], ylabel=f\"{n_fft=}\", ax=axs[i])\n",
    "    axs[i].set_xlabel(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 50\n",
    "\n",
    "waveform = windowed_data.type(torch.float32)\n",
    "waveform = torchaudio.transforms.Resample(sample_rate, Fs)(waveform)\n",
    "spectrogram_transform = torchaudio.transforms.Spectrogram(\n",
    "            n_fft=256, \n",
    "            win_length=24,\n",
    "            hop_length=1, \n",
    "            window_fn=torch.hann_window ,\n",
    "        )\n",
    "\n",
    "resample_ratio = 320/waveform.shape[1]\n",
    "resample_target = int(100*resample_ratio)\n",
    "waveform = torchaudio.transforms.Resample(100, resample_target)(waveform)\n",
    "spectrogram = spectrogram_transform(waveform) # from [1,320] to [1,129,321]\n",
    "spectrogram_db = torchaudio.transforms.AmplitudeToDB()(spectrogram)\n",
    "fbank = spectrogram_db.squeeze(0).transpose(0,1)[:,:128]\n",
    "plot_spectrogram(spectrogram_db[3], ylabel=\"freq_bin\", ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram_db.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EgoExo4D: Pytorch dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%cd src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from data.egoexo4d import EgoExo4D\n",
    "import torch\n",
    "from torch.nn import DataParallel\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the json file\n",
    "# takes = pd.read_json(os.path.join(ego_exo_root, 'takes.json'))\n",
    "ego_exo_root = os.path.join('/data2', 'EgoExo4D') # Replace with your cli's download directory for Ego-Exo4D\n",
    "data_dir = os.path.join('/data2', 'EgoExo4D')\n",
    "takes = json.load(open(os.path.join(ego_exo_root, 'takes.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECGRAM_PARAMS = {\n",
    "    'window_size': 2,\n",
    "    'n_fft': 128,\n",
    "    'hop_length': 4,\n",
    "    'sampling_rate': 1e3,\n",
    "    'downsampling_rate': 500,\n",
    "    'transforms': None,\n",
    "    'resizes': (64, 192),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "takes[0]['duration_sec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_uid = takes[0]['take_uid']\n",
    "omnivore_filename = take_uid + '_' + 'aria01_rgb.pt'\n",
    "take_path = os.path.join(data_dir, 'features', 'omnivore_video')\n",
    "omnivore = torch.load(os.path.join(take_path, omnivore_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omnivore.shape[0], omnivore.shape[-1] / (3 * 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omnivore[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EgoExo4D(data_dir, 'imu_aria01', ['imu-right'], **SPECGRAM_PARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filename = '/data2/EgoExo4D/takes/cmu_bike01_2/trajectory/closed_loop_trajectory.csv'\n",
    "trajectory = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory['tracking_timestamp_us'] = trajectory['tracking_timestamp_us'] / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory[['tracking_timestamp_us', 'device_linear_velocity_x_device',\n",
    "       'device_linear_velocity_y_device', 'device_linear_velocity_z_device']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory['tracking_timestamp_us'].iloc[-1] - trajectory['tracking_timestamp_us'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory[['device_linear_velocity_x_device',\n",
    "       'device_linear_velocity_y_device', 'device_linear_velocity_z_device']].max(), trajectory[['device_linear_velocity_x_device',\n",
    "         'device_linear_velocity_y_device', 'device_linear_velocity_z_device']].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio-mae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
